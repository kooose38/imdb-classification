{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59b87075-89a9-4f0b-b178-c86274d269ba",
   "metadata": {},
   "source": [
    "### load dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc176552-09c3-4fa7-9a9c-aca7d87a01f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_data import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2e88077-bd82-4739-9131-60fe48c08be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 128])\n"
     ]
    }
   ],
   "source": [
    "train, val, test = dataset.transform(max_length=128)\n",
    "\n",
    "for t in train:\n",
    "    sample = t[\"input_ids\"]\n",
    "    mask = t[\"attention_mask\"]\n",
    "    token = t[\"token_type_ids\"]\n",
    "    labels = t[\"labels\"]\n",
    "    print(sample.size())\n",
    "    break "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda55aaf-5781-4f50-a290-68595b49f35a",
   "metadata": {},
   "source": [
    "### training step\n",
    "\n",
    "+ saving local in `.onnc` model and `.pth` model_weights\n",
    "+ upload s3 \n",
    "+ add info to `MODEL_DB`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0575358e-9ab3-49a5-a5a1-e3b028a0e56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:networks.weights.load_weights_from_s3:loading s3 from https://imdb-classification.s3.ap-northeast-1.amazonaws.com/bert/pytorch_model.bin\n",
      "INFO:networks.weights.load_weights_from_s3:complete read uri duraion in senconds: 928.8808689117432\n"
     ]
    }
   ],
   "source": [
    "from networks.classifier_net import BertForIMDBClassification\n",
    "from networks.load_config import config\n",
    "\n",
    "\n",
    "net = BertForIMDBClassification(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4367aeda-f79f-45c3-8852-a8137a2b08b8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### look at BertModel paramters \n",
    "check requierd_grad == **False**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe6c189d-65fc-497f-a063-6ead3ab85336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert.embedd.embeddings.weight\n",
      "------------------------------\n",
      "bert.embedd.position_embeddings.weight\n",
      "------------------------------\n",
      "bert.embedd.token_type_embeddings.weight\n",
      "------------------------------\n",
      "bert.embedd.norm.gamma\n",
      "------------------------------\n",
      "bert.embedd.norm.beta\n",
      "------------------------------\n",
      "bert.encode.layers.0.attnet.attnet.query.weight\n",
      "------------------------------\n",
      "bert.encode.layers.0.attnet.attnet.query.bias\n",
      "------------------------------\n",
      "bert.encode.layers.0.attnet.attnet.key.weight\n",
      "------------------------------\n",
      "bert.encode.layers.0.attnet.attnet.key.bias\n",
      "------------------------------\n",
      "bert.encode.layers.0.attnet.attnet.value.weight\n",
      "------------------------------\n",
      "bert.encode.layers.0.attnet.attnet.value.bias\n",
      "------------------------------\n",
      "bert.encode.layers.0.attnet.attout.dense.weight\n",
      "------------------------------\n",
      "bert.encode.layers.0.attnet.attout.dense.bias\n",
      "------------------------------\n",
      "bert.encode.layers.0.attnet.attout.LayerNorm.gamma\n",
      "------------------------------\n",
      "bert.encode.layers.0.attnet.attout.LayerNorm.beta\n",
      "------------------------------\n",
      "bert.encode.layers.0.intermadiate.fc.0.weight\n",
      "------------------------------\n",
      "bert.encode.layers.0.intermadiate.fc.0.bias\n",
      "------------------------------\n",
      "bert.encode.layers.0.out.fc.0.weight\n",
      "------------------------------\n",
      "bert.encode.layers.0.out.fc.0.bias\n",
      "------------------------------\n",
      "bert.encode.layers.0.out.norm.gamma\n",
      "------------------------------\n",
      "bert.encode.layers.0.out.norm.beta\n",
      "------------------------------\n",
      "bert.encode.layers.1.attnet.attnet.query.weight\n",
      "------------------------------\n",
      "bert.encode.layers.1.attnet.attnet.query.bias\n",
      "------------------------------\n",
      "bert.encode.layers.1.attnet.attnet.key.weight\n",
      "------------------------------\n",
      "bert.encode.layers.1.attnet.attnet.key.bias\n",
      "------------------------------\n",
      "bert.encode.layers.1.attnet.attnet.value.weight\n",
      "------------------------------\n",
      "bert.encode.layers.1.attnet.attnet.value.bias\n",
      "------------------------------\n",
      "bert.encode.layers.1.attnet.attout.dense.weight\n",
      "------------------------------\n",
      "bert.encode.layers.1.attnet.attout.dense.bias\n",
      "------------------------------\n",
      "bert.encode.layers.1.attnet.attout.LayerNorm.gamma\n",
      "------------------------------\n",
      "bert.encode.layers.1.attnet.attout.LayerNorm.beta\n",
      "------------------------------\n",
      "bert.encode.layers.1.intermadiate.fc.0.weight\n",
      "------------------------------\n",
      "bert.encode.layers.1.intermadiate.fc.0.bias\n",
      "------------------------------\n",
      "bert.encode.layers.1.out.fc.0.weight\n",
      "------------------------------\n",
      "bert.encode.layers.1.out.fc.0.bias\n",
      "------------------------------\n",
      "bert.encode.layers.1.out.norm.gamma\n",
      "------------------------------\n",
      "bert.encode.layers.1.out.norm.beta\n",
      "------------------------------\n",
      "bert.encode.layers.2.attnet.attnet.query.weight\n",
      "------------------------------\n",
      "bert.encode.layers.2.attnet.attnet.query.bias\n",
      "------------------------------\n",
      "bert.encode.layers.2.attnet.attnet.key.weight\n",
      "------------------------------\n",
      "bert.encode.layers.2.attnet.attnet.key.bias\n",
      "------------------------------\n",
      "bert.encode.layers.2.attnet.attnet.value.weight\n",
      "------------------------------\n",
      "bert.encode.layers.2.attnet.attnet.value.bias\n",
      "------------------------------\n",
      "bert.encode.layers.2.attnet.attout.dense.weight\n",
      "------------------------------\n",
      "bert.encode.layers.2.attnet.attout.dense.bias\n",
      "------------------------------\n",
      "bert.encode.layers.2.attnet.attout.LayerNorm.gamma\n",
      "------------------------------\n",
      "bert.encode.layers.2.attnet.attout.LayerNorm.beta\n",
      "------------------------------\n",
      "bert.encode.layers.2.intermadiate.fc.0.weight\n",
      "------------------------------\n",
      "bert.encode.layers.2.intermadiate.fc.0.bias\n",
      "------------------------------\n",
      "bert.encode.layers.2.out.fc.0.weight\n",
      "------------------------------\n",
      "bert.encode.layers.2.out.fc.0.bias\n",
      "------------------------------\n",
      "bert.encode.layers.2.out.norm.gamma\n",
      "------------------------------\n",
      "bert.encode.layers.2.out.norm.beta\n",
      "------------------------------\n",
      "bert.encode.layers.3.attnet.attnet.query.weight\n",
      "------------------------------\n",
      "bert.encode.layers.3.attnet.attnet.query.bias\n",
      "------------------------------\n",
      "bert.encode.layers.3.attnet.attnet.key.weight\n",
      "------------------------------\n",
      "bert.encode.layers.3.attnet.attnet.key.bias\n",
      "------------------------------\n",
      "bert.encode.layers.3.attnet.attnet.value.weight\n",
      "------------------------------\n",
      "bert.encode.layers.3.attnet.attnet.value.bias\n",
      "------------------------------\n",
      "bert.encode.layers.3.attnet.attout.dense.weight\n",
      "------------------------------\n",
      "bert.encode.layers.3.attnet.attout.dense.bias\n",
      "------------------------------\n",
      "bert.encode.layers.3.attnet.attout.LayerNorm.gamma\n",
      "------------------------------\n",
      "bert.encode.layers.3.attnet.attout.LayerNorm.beta\n",
      "------------------------------\n",
      "bert.encode.layers.3.intermadiate.fc.0.weight\n",
      "------------------------------\n",
      "bert.encode.layers.3.intermadiate.fc.0.bias\n",
      "------------------------------\n",
      "bert.encode.layers.3.out.fc.0.weight\n",
      "------------------------------\n",
      "bert.encode.layers.3.out.fc.0.bias\n",
      "------------------------------\n",
      "bert.encode.layers.3.out.norm.gamma\n",
      "------------------------------\n",
      "bert.encode.layers.3.out.norm.beta\n",
      "------------------------------\n",
      "bert.encode.layers.4.attnet.attnet.query.weight\n",
      "------------------------------\n",
      "bert.encode.layers.4.attnet.attnet.query.bias\n",
      "------------------------------\n",
      "bert.encode.layers.4.attnet.attnet.key.weight\n",
      "------------------------------\n",
      "bert.encode.layers.4.attnet.attnet.key.bias\n",
      "------------------------------\n",
      "bert.encode.layers.4.attnet.attnet.value.weight\n",
      "------------------------------\n",
      "bert.encode.layers.4.attnet.attnet.value.bias\n",
      "------------------------------\n",
      "bert.encode.layers.4.attnet.attout.dense.weight\n",
      "------------------------------\n",
      "bert.encode.layers.4.attnet.attout.dense.bias\n",
      "------------------------------\n",
      "bert.encode.layers.4.attnet.attout.LayerNorm.gamma\n",
      "------------------------------\n",
      "bert.encode.layers.4.attnet.attout.LayerNorm.beta\n",
      "------------------------------\n",
      "bert.encode.layers.4.intermadiate.fc.0.weight\n",
      "------------------------------\n",
      "bert.encode.layers.4.intermadiate.fc.0.bias\n",
      "------------------------------\n",
      "bert.encode.layers.4.out.fc.0.weight\n",
      "------------------------------\n",
      "bert.encode.layers.4.out.fc.0.bias\n",
      "------------------------------\n",
      "bert.encode.layers.4.out.norm.gamma\n",
      "------------------------------\n",
      "bert.encode.layers.4.out.norm.beta\n",
      "------------------------------\n",
      "bert.encode.layers.5.attnet.attnet.query.weight\n",
      "------------------------------\n",
      "bert.encode.layers.5.attnet.attnet.query.bias\n",
      "------------------------------\n",
      "bert.encode.layers.5.attnet.attnet.key.weight\n",
      "------------------------------\n",
      "bert.encode.layers.5.attnet.attnet.key.bias\n",
      "------------------------------\n",
      "bert.encode.layers.5.attnet.attnet.value.weight\n",
      "------------------------------\n",
      "bert.encode.layers.5.attnet.attnet.value.bias\n",
      "------------------------------\n",
      "bert.encode.layers.5.attnet.attout.dense.weight\n",
      "------------------------------\n",
      "bert.encode.layers.5.attnet.attout.dense.bias\n",
      "------------------------------\n",
      "bert.encode.layers.5.attnet.attout.LayerNorm.gamma\n",
      "------------------------------\n",
      "bert.encode.layers.5.attnet.attout.LayerNorm.beta\n",
      "------------------------------\n",
      "bert.encode.layers.5.intermadiate.fc.0.weight\n",
      "------------------------------\n",
      "bert.encode.layers.5.intermadiate.fc.0.bias\n",
      "------------------------------\n",
      "bert.encode.layers.5.out.fc.0.weight\n",
      "------------------------------\n",
      "bert.encode.layers.5.out.fc.0.bias\n",
      "------------------------------\n",
      "bert.encode.layers.5.out.norm.gamma\n",
      "------------------------------\n",
      "bert.encode.layers.5.out.norm.beta\n",
      "------------------------------\n",
      "bert.encode.layers.6.attnet.attnet.query.weight\n",
      "------------------------------\n",
      "bert.encode.layers.6.attnet.attnet.query.bias\n",
      "------------------------------\n",
      "bert.encode.layers.6.attnet.attnet.key.weight\n",
      "------------------------------\n",
      "bert.encode.layers.6.attnet.attnet.key.bias\n",
      "------------------------------\n",
      "bert.encode.layers.6.attnet.attnet.value.weight\n",
      "------------------------------\n",
      "bert.encode.layers.6.attnet.attnet.value.bias\n",
      "------------------------------\n",
      "bert.encode.layers.6.attnet.attout.dense.weight\n",
      "------------------------------\n",
      "bert.encode.layers.6.attnet.attout.dense.bias\n",
      "------------------------------\n",
      "bert.encode.layers.6.attnet.attout.LayerNorm.gamma\n",
      "------------------------------\n",
      "bert.encode.layers.6.attnet.attout.LayerNorm.beta\n",
      "------------------------------\n",
      "bert.encode.layers.6.intermadiate.fc.0.weight\n",
      "------------------------------\n",
      "bert.encode.layers.6.intermadiate.fc.0.bias\n",
      "------------------------------\n",
      "bert.encode.layers.6.out.fc.0.weight\n",
      "------------------------------\n",
      "bert.encode.layers.6.out.fc.0.bias\n",
      "------------------------------\n",
      "bert.encode.layers.6.out.norm.gamma\n",
      "------------------------------\n",
      "bert.encode.layers.6.out.norm.beta\n",
      "------------------------------\n",
      "bert.encode.layers.7.attnet.attnet.query.weight\n",
      "------------------------------\n",
      "bert.encode.layers.7.attnet.attnet.query.bias\n",
      "------------------------------\n",
      "bert.encode.layers.7.attnet.attnet.key.weight\n",
      "------------------------------\n",
      "bert.encode.layers.7.attnet.attnet.key.bias\n",
      "------------------------------\n",
      "bert.encode.layers.7.attnet.attnet.value.weight\n",
      "------------------------------\n",
      "bert.encode.layers.7.attnet.attnet.value.bias\n",
      "------------------------------\n",
      "bert.encode.layers.7.attnet.attout.dense.weight\n",
      "------------------------------\n",
      "bert.encode.layers.7.attnet.attout.dense.bias\n",
      "------------------------------\n",
      "bert.encode.layers.7.attnet.attout.LayerNorm.gamma\n",
      "------------------------------\n",
      "bert.encode.layers.7.attnet.attout.LayerNorm.beta\n",
      "------------------------------\n",
      "bert.encode.layers.7.intermadiate.fc.0.weight\n",
      "------------------------------\n",
      "bert.encode.layers.7.intermadiate.fc.0.bias\n",
      "------------------------------\n",
      "bert.encode.layers.7.out.fc.0.weight\n",
      "------------------------------\n",
      "bert.encode.layers.7.out.fc.0.bias\n",
      "------------------------------\n",
      "bert.encode.layers.7.out.norm.gamma\n",
      "------------------------------\n",
      "bert.encode.layers.7.out.norm.beta\n",
      "------------------------------\n",
      "bert.encode.layers.8.attnet.attnet.query.weight\n",
      "------------------------------\n",
      "bert.encode.layers.8.attnet.attnet.query.bias\n",
      "------------------------------\n",
      "bert.encode.layers.8.attnet.attnet.key.weight\n",
      "------------------------------\n",
      "bert.encode.layers.8.attnet.attnet.key.bias\n",
      "------------------------------\n",
      "bert.encode.layers.8.attnet.attnet.value.weight\n",
      "------------------------------\n",
      "bert.encode.layers.8.attnet.attnet.value.bias\n",
      "------------------------------\n",
      "bert.encode.layers.8.attnet.attout.dense.weight\n",
      "------------------------------\n",
      "bert.encode.layers.8.attnet.attout.dense.bias\n",
      "------------------------------\n",
      "bert.encode.layers.8.attnet.attout.LayerNorm.gamma\n",
      "------------------------------\n",
      "bert.encode.layers.8.attnet.attout.LayerNorm.beta\n",
      "------------------------------\n",
      "bert.encode.layers.8.intermadiate.fc.0.weight\n",
      "------------------------------\n",
      "bert.encode.layers.8.intermadiate.fc.0.bias\n",
      "------------------------------\n",
      "bert.encode.layers.8.out.fc.0.weight\n",
      "------------------------------\n",
      "bert.encode.layers.8.out.fc.0.bias\n",
      "------------------------------\n",
      "bert.encode.layers.8.out.norm.gamma\n",
      "------------------------------\n",
      "bert.encode.layers.8.out.norm.beta\n",
      "------------------------------\n",
      "bert.encode.layers.9.attnet.attnet.query.weight\n",
      "------------------------------\n",
      "bert.encode.layers.9.attnet.attnet.query.bias\n",
      "------------------------------\n",
      "bert.encode.layers.9.attnet.attnet.key.weight\n",
      "------------------------------\n",
      "bert.encode.layers.9.attnet.attnet.key.bias\n",
      "------------------------------\n",
      "bert.encode.layers.9.attnet.attnet.value.weight\n",
      "------------------------------\n",
      "bert.encode.layers.9.attnet.attnet.value.bias\n",
      "------------------------------\n",
      "bert.encode.layers.9.attnet.attout.dense.weight\n",
      "------------------------------\n",
      "bert.encode.layers.9.attnet.attout.dense.bias\n",
      "------------------------------\n",
      "bert.encode.layers.9.attnet.attout.LayerNorm.gamma\n",
      "------------------------------\n",
      "bert.encode.layers.9.attnet.attout.LayerNorm.beta\n",
      "------------------------------\n",
      "bert.encode.layers.9.intermadiate.fc.0.weight\n",
      "------------------------------\n",
      "bert.encode.layers.9.intermadiate.fc.0.bias\n",
      "------------------------------\n",
      "bert.encode.layers.9.out.fc.0.weight\n",
      "------------------------------\n",
      "bert.encode.layers.9.out.fc.0.bias\n",
      "------------------------------\n",
      "bert.encode.layers.9.out.norm.gamma\n",
      "------------------------------\n",
      "bert.encode.layers.9.out.norm.beta\n",
      "------------------------------\n",
      "bert.encode.layers.10.attnet.attnet.query.weight\n",
      "------------------------------\n",
      "bert.encode.layers.10.attnet.attnet.query.bias\n",
      "------------------------------\n",
      "bert.encode.layers.10.attnet.attnet.key.weight\n",
      "------------------------------\n",
      "bert.encode.layers.10.attnet.attnet.key.bias\n",
      "------------------------------\n",
      "bert.encode.layers.10.attnet.attnet.value.weight\n",
      "------------------------------\n",
      "bert.encode.layers.10.attnet.attnet.value.bias\n",
      "------------------------------\n",
      "bert.encode.layers.10.attnet.attout.dense.weight\n",
      "------------------------------\n",
      "bert.encode.layers.10.attnet.attout.dense.bias\n",
      "------------------------------\n",
      "bert.encode.layers.10.attnet.attout.LayerNorm.gamma\n",
      "------------------------------\n",
      "bert.encode.layers.10.attnet.attout.LayerNorm.beta\n",
      "------------------------------\n",
      "bert.encode.layers.10.intermadiate.fc.0.weight\n",
      "------------------------------\n",
      "bert.encode.layers.10.intermadiate.fc.0.bias\n",
      "------------------------------\n",
      "bert.encode.layers.10.out.fc.0.weight\n",
      "------------------------------\n",
      "bert.encode.layers.10.out.fc.0.bias\n",
      "------------------------------\n",
      "bert.encode.layers.10.out.norm.gamma\n",
      "------------------------------\n",
      "bert.encode.layers.10.out.norm.beta\n",
      "------------------------------\n",
      "bert.encode.layers.11.attnet.attnet.query.weight\n",
      "------------------------------\n",
      "bert.encode.layers.11.attnet.attnet.query.bias\n",
      "------------------------------\n",
      "bert.encode.layers.11.attnet.attnet.key.weight\n",
      "------------------------------\n",
      "bert.encode.layers.11.attnet.attnet.key.bias\n",
      "------------------------------\n",
      "bert.encode.layers.11.attnet.attnet.value.weight\n",
      "------------------------------\n",
      "bert.encode.layers.11.attnet.attnet.value.bias\n",
      "------------------------------\n",
      "bert.encode.layers.11.attnet.attout.dense.weight\n",
      "------------------------------\n",
      "bert.encode.layers.11.attnet.attout.dense.bias\n",
      "------------------------------\n",
      "bert.encode.layers.11.attnet.attout.LayerNorm.gamma\n",
      "------------------------------\n",
      "bert.encode.layers.11.attnet.attout.LayerNorm.beta\n",
      "------------------------------\n",
      "bert.encode.layers.11.intermadiate.fc.0.weight\n",
      "------------------------------\n",
      "bert.encode.layers.11.intermadiate.fc.0.bias\n",
      "------------------------------\n",
      "bert.encode.layers.11.out.fc.0.weight\n",
      "------------------------------\n",
      "bert.encode.layers.11.out.fc.0.bias\n",
      "------------------------------\n",
      "bert.encode.layers.11.out.norm.gamma\n",
      "------------------------------\n",
      "bert.encode.layers.11.out.norm.beta\n",
      "------------------------------\n",
      "bert.decode.fc.0.weight\n",
      "------------------------------\n",
      "bert.decode.fc.0.bias\n",
      "------------------------------\n",
      "fc.weight\n",
      "------------------------------\n",
      "fc.bias\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "for name, weight in net.named_parameters():\n",
    "    print(name)\n",
    "#     print(weight)\n",
    "    print(\"-\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23d2a37a-a31e-4d2b-80ec-d8316c5508f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:trainer:start training ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kooose/my-lab/imdb-classification/work/models/bert/networks/bertmodel/attention_net.py:57: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  weigths = torch.nn.functional.softmax(weights) #ここで<pad>の部分はほぼ0になる\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SummaryWriter' object has no attribute 'add_scaler'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_196/944767294.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mresults_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"training step 1 counts\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/my-lab/imdb-classification/work/models/bert/trainer.py\u001b[0m in \u001b[0;36mtrainer\u001b[0;34m(train, val, model, criterion, optimizer, num_epochs, description)\u001b[0m\n\u001b[1;32m     45\u001b[0m       \u001b[0mn_train\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m       \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/total_loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m       \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss/train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SummaryWriter' object has no attribute 'add_scaler'"
     ]
    }
   ],
   "source": [
    "from trainer import trainer \n",
    "import torch \n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=2e-5)\n",
    "\n",
    "results_model = trainer(train, val, net, criterion, optimizer, 10, \"training step 1 counts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff9bf7b-adef-45b5-90e4-03d88ba49643",
   "metadata": {},
   "source": [
    "### testing step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0fc6d90f-20be-4195-b067-f3ef96cad75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                         | 0/313 [00:00<?, ?it/s]/home/kooose/my-lab/imdb-classification/work/models/bert/networks/bertmodel/attention_net.py:57: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  weigths = torch.nn.functional.softmax(weights) #ここで<pad>の部分はほぼ0になる\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 313/313 [00:53<00:00,  5.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.082355 accuracy: 0.494200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from evaluate import evaluate \n",
    "\n",
    "evaluate(test, results_model, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d434f1-9b08-41eb-93ab-4b73eae9e1ef",
   "metadata": {},
   "source": [
    "### saving prediction functions `.pkl`\n",
    "* local \n",
    "* S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da32dd08-9a34-4eb2-a14b-61b124d4a5d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pred.make_pkl:upload file to s3 ... \n",
      "INFO:pred.make_pkl:complete upload files !!!\n",
      "INFO:pred.make_pkl:upload file to s3 ... \n",
      "INFO:pred.make_pkl:complete upload files !!!\n"
     ]
    }
   ],
   "source": [
    "from pred.prediction import pred\n",
    "from pred.preprocessing import prep\n",
    "from pred.make_pkl import make_dump_prep, upload_s3_bucket \n",
    "\n",
    "make_dump_prep(prep)\n",
    "filename_pred = \"./pred/prediction/predicion_bert.pkl\"\n",
    "make_dump_prep(pred, filename_pred)\n",
    "\n",
    "upload_s3_bucket()\n",
    "upload_s3_bucket(filename_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f227b64-6d12-42f1-8583-e2c01a5f18dc",
   "metadata": {},
   "source": [
    "### Attetion weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe95b2b2-0d03-4d0a-854a-27caa81f1bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 12, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    output, weigths = net(sample, token, mask, attention_flg=True) \n",
    "    \n",
    "print(weigths.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e8ab30cb-e736-472c-8b1c-ba3116310790",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './pred/prediction/predction.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_196/2449025060.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmk_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_attn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweigths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/my-lab/imdb-classification/work/models/bert/visualization_attetion.py\u001b[0m in \u001b[0;36mmk_html\u001b[0;34m(index, sample, preds, attn_weight1)\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m   \u001b[0mpred_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dump_prep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./pred/prediction/predction.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m   \u001b[0msentence_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/my-lab/imdb-classification/work/models/bert/pred/make_pkl.py\u001b[0m in \u001b[0;36mload_dump_prep\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_dump_prep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./pred/preprocessing/preprocessing_bert.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   \u001b[0mprep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mprep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/my-lab/imdb-classification/lib/python3.8/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_read_fileobject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap_mode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './pred/prediction/predction.pkl'"
     ]
    }
   ],
   "source": [
    "from visualization_attetion import mk_html\n",
    "from IPython.display import HTML\n",
    "\n",
    "pred = output.argmax(-1)\n",
    "\n",
    "sample_attn = None \n",
    "for r in train:\n",
    "    sample_attn = r \n",
    "    break \n",
    "    \n",
    "index = 1\n",
    "    \n",
    "html = mk_html(index, sample_attn, pred, weigths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f057e782-d966-4c84-bfea-e60a2857c4a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "866b63dd-1fd6-4556-b9e4-d54d02af8d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = output.argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416fad66-5b26-4d51-9d9b-5525bc34b739",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
